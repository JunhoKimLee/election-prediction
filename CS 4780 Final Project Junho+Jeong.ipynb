{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CS 4780/5780 Final Project: </h2>\n",
    "<h3>Election Result Prediction for US Counties</h3>\n",
    "\n",
    "Names and NetIDs for your group members: Junho Kim-Lee (jk2333), Jeong Hyun Lee (jl2374)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction:</h3>\n",
    "\n",
    "<p> The final project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The programming project provide templates for how to do this, and the most recent video lectures summarize some of the tricks you will need (e.g. feature normalization, feature construction). So, this final project brings realism to how you will use machine learning in the real world.  </p>\n",
    "\n",
    "<p> The task you will work on is forecasting election results. Economic and sociological factors have been widely used when making predictions on the voting results of US elections. Economic and sociological factors vary a lot among counties in the United States. In addition, as you may observe from the election map of recent elections, neighbor counties show similar patterns in terms of the voting results. In this project you will bring the power of machine learning to make predictions for the county-level election results using Economic and sociological factors and the geographic structure of US counties. </p>\n",
    "\n",
    "\n",
    "<h3>Your Task:</h3>\n",
    "Plase read the project description PDF file carefully and make sure you write your code and answers to all the questions in this Jupyter Notebook. Your answers to the questions are a large portion of your grade for this final project. Please import the packages in this notebook and cite any references you used as mentioned in the project description. You need to print this entire Jupyter Notebook as a PDF file and submit to Gradescope and also submit the ipynb runnable version to Canvas for us to run.\n",
    "\n",
    "<h3>Due Date:</h3>\n",
    "The final project dataset and template jupyter notebook will be due on <strong>December 15th</strong> . Note that <strong>no late submissions will be accepted</strong>  and you cannot use any of your unused slip days before."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Basics</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Import:</h3><p>\n",
    "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
    "    \n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "    \n",
    "https://pytorch.org/tutorials/\n",
    "    \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# TODO\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Weighted Accuracy:</h3><p>\n",
    "Since our dataset labels are heavily biased, you need to use the following function to compute weighted accuracy throughout your training and validation process and we use this for testing on Kaggle.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_accuracy(pred, true):\n",
    "    assert(len(pred) == len(true))\n",
    "    num_labels = len(true)\n",
    "    num_pos = sum(true)\n",
    "    num_neg = num_labels - num_pos\n",
    "    frac_pos = num_pos/num_labels\n",
    "    weight_pos = 1/frac_pos\n",
    "    weight_neg = 1/(1-frac_pos)\n",
    "    num_pos_correct = 0\n",
    "    num_neg_correct = 0\n",
    "    for pred_i, true_i in zip(pred, true):\n",
    "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
    "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
    "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
    "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
    "    return weighted_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Baseline Solution</h2><p>\n",
    "Note that your code should be commented well and in part 2.4 you can refer to your comments. (e.g. &#35; Here is SVM, \n",
    "&#35; Here is validation for SVM, etc). Also, we recommend that you do not to use 2012 dataset and the graph dataset to reach the baseline accuracy for 68% in this part, a basic solution with only 2016 dataset and reasonable model selection will be enough, it will be great if you explore the graph and possibly 2012 dataset in Part 3.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Preprocessing and Feature Extraction:</h3><p>\n",
    "Given the training dataset and graph information, you need to correctly preprocess the dataset (e.g. feature normalization). For baseline solution in this part, you might not need to introduce extra features to reach the baseline test accuracy.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change this but we suggest loading data with the following code and you may need to change\n",
    "# datatypes and do necessary data transformation after loading the raw data to the dataframe.\n",
    "\n",
    "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
    "\n",
    "def preprocess(path, labels = True):\n",
    "    df = pd.read_csv(path, sep=',',header=0, encoding='unicode_escape')\n",
    "\n",
    "    # drop non-numerical columns\n",
    "    df = df.drop('County', axis=1)\n",
    "\n",
    "    # type conversions\n",
    "    for col in df.columns:\n",
    "        if col == 'DEM' or col == 'GOP':\n",
    "            df[col] = df[col].astype(int)\n",
    "        elif col == 'MedianIncome':\n",
    "            df[col] = df[col].str.replace(\",\",\"\").astype(int)\n",
    "        elif col == 'FIPS':\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            df[col] = df[col].astype(float)\n",
    "\n",
    "    # replace DEM/GOP columns with a binary results array\n",
    "    if labels == True:\n",
    "        yTr = np.where(df['DEM'] > df['GOP'], 1, 0)\n",
    "        df = df.drop('DEM', axis=1)\n",
    "        df = df.drop('GOP', axis=1)\n",
    "    else:\n",
    "        yTr = df['FIPS']    # for carrying over FIPS ID for testing data\n",
    "\n",
    "    # drop FIPS after potentially storing it to yTr\n",
    "    df = df.drop('FIPS', axis=1)\n",
    "            \n",
    "    # normalize\n",
    "    xTr = preprocessing.StandardScaler().fit_transform(df)\n",
    "    \n",
    "    return xTr, yTr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
    "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
    "\n",
    "# create a neural network with custom inputs for hyperparameters\n",
    "# outputs predicted values for given test set xTe\n",
    "def neural(xTe, xTr, yTr, h, a, al, m):\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes = h,\n",
    "        activation = a,\n",
    "        alpha = al,\n",
    "        max_iter = m,\n",
    "        random_state = 7\n",
    "    )\n",
    "    clf.fit(xTr,yTr)\n",
    "    yTe = clf.predict(xTe)\n",
    "    \n",
    "    return yTe\n",
    "\n",
    "# create a SVM classification function with custom inputs for hyperparameters C, kernel, and gamma\n",
    "# outputs predicted values for given test set xTe\n",
    "def SVM(xTe, xTr, yTr, C, k, g=\"scale\"):\n",
    "    classifier = svm.SVC(C, kernel = k, gamma = g)\n",
    "    classifier.fit(xTr, yTr)\n",
    "    yTe = classifier.predict(xTe)\n",
    "    return yTe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.3 Training, Validation and Model Selection:</h3><p>\n",
    "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
    "# TODO\n",
    "\n",
    "# read in training data and return xTr, yTr, xTe, yTe with an 80/20 split\n",
    "def get_split_data(path):\n",
    "    xTr, yTr = preprocess(path)\n",
    "    return train_test_split(xTr, yTr, test_size=.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# validate neural network to choose best custom parameters that leads to highest testing accuracy.\n",
    "# 80/20 split into training and validation sets.\n",
    "def neural_val():\n",
    "    \n",
    "    # split into test/train/val sets\n",
    "    xTr,xTe,yTr,yTe = get_split_data(\"train_2016.csv\")\n",
    "    xTr,xVal,yTr,yVal = train_test_split(xTr, yTr, test_size=.2, random_state=7)\n",
    "    \n",
    "    # hyperparameters\n",
    "    hidden_layer_sizes = np.arange(80,101,5)\n",
    "    activation = ['logistic','tanh','relu']\n",
    "    alpha = [.000001,.00001,.0001]\n",
    "    max_iter = np.arange(1000,3001,500)\n",
    "\n",
    "    # tracker for best neural net parameters\n",
    "    best = (\n",
    "        hidden_layer_sizes[0],\n",
    "        activation[0],\n",
    "        alpha[0],\n",
    "        max_iter[0]\n",
    "           )\n",
    "    best_a = -1\n",
    "\n",
    "    # validate until we have selected good parameters\n",
    "    start = time.time()\n",
    "    z = 1\n",
    "    for h in hidden_layer_sizes:\n",
    "        for a in activation:\n",
    "            for al in alpha:\n",
    "                for m in max_iter:\n",
    "                    yVal_emp = neural(xVal, xTr, yTr, h, a, al, m,)\n",
    "                    acc = weighted_accuracy(yVal_emp, yVal)\n",
    "                    if acc > best_a:\n",
    "                        best_a = acc\n",
    "                        best = (h,a,al,m)           \n",
    "\n",
    "                # progress tracker\n",
    "                print(str(math.floor(z*100/45))+\"% done. Time to completion: \"+ \n",
    "                      str(round(((time.time()-start)/z)*(45-z),0)) +\" seconds.\")\n",
    "                z += 1            \n",
    "    print(\"Validation finished after \"+str(round(time.time()-start,0))+\" seconds.\")\n",
    "\n",
    "    # test the best model with the test set\n",
    "    yTe_emp = neural(xTe, xTr, yTr,best[0],best[1],best[2],best[3])\n",
    "    acc = weighted_accuracy(yTe_emp, yTe)\n",
    "\n",
    "    # print outputs\n",
    "    print(\"Hidden Layer Size: \" + str(best[0]))\n",
    "    print(\"Activation: \" + best[1])\n",
    "    print(\"Alpha: \" + str(best[2]))\n",
    "    print(\"Max Iterations: \" + str(best[3]))\n",
    "    print(\"Validation Accuracy: \" + str(round(best_a*100,2)) + \"%\")\n",
    "    print(\"Test Accuracy: \" + str(round(acc*100,2)) + \"%\")\n",
    "    \n",
    "    return acc, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate svm to choose best custom parameters that leads to highest testing accuracy.\n",
    "# 10-fold cross-validation.\n",
    "def svm_val():\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_split_data(\"train_2016.csv\")\n",
    "\n",
    "    # hyperparameters for SVM\n",
    "    parameters_C = np.arange(1, 20, 1)\n",
    "    parameters_kernel = ('linear', 'poly', 'rbf', 'sigmoid')\n",
    "    parameters_gamma = [1, 0.1, 0.01, 0.001, \"scale\", \"auto\"]\n",
    "\n",
    "    bestC = 0\n",
    "    bestKernel = \"\"\n",
    "    bestGamma = 0\n",
    "    bestScore = 0\n",
    "\n",
    "    # K-fold CV that tunes three hyperparameters\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    # keep track of runtime and progress\n",
    "    start = time.time()\n",
    "    z = 1\n",
    "\n",
    "    # three loops for the three hyperparameters\n",
    "    for C in parameters_C:\n",
    "        for kernel in parameters_kernel:\n",
    "            for gamma in parameters_gamma:\n",
    "                scores = []\n",
    "                # 10-fold CV\n",
    "                for train_index, test_index in kf.split(X_train):\n",
    "                    X_train_split, X_test_split = X_train[train_index], X_train[test_index]\n",
    "                    y_train_split, y_test_split = y_train[train_index], y_train[test_index]\n",
    "\n",
    "                    preds = SVM(X_test_split, X_train_split, y_train_split, C, kernel, gamma)\n",
    "                    scores.append(weighted_accuracy(preds, y_test_split))\n",
    "\n",
    "                # get average score across the 10-fold CV\n",
    "                score = np.mean(scores)\n",
    "                \n",
    "                # record best score and its hyperparameters\n",
    "                if score > bestScore:\n",
    "                    bestScore = score\n",
    "                    bestC = C\n",
    "                    bestGamma = gamma\n",
    "                    bestKernel = kernel\n",
    "                # progress tracker\n",
    "                print(str(math.floor(z*100/(len(parameters_C)*len(parameters_gamma)*len(parameters_kernel))))\n",
    "                      + \"% done. Time to completion: \"\n",
    "                      + str(round(((time.time()-start)/z)\n",
    "                                  * ((len(parameters_C)*len(parameters_gamma)*len(parameters_kernel))-z),0)) +\" seconds.\")\n",
    "                z += 1\n",
    "    print(\"Validation finished after \"+str(round(time.time()-start,0))+\" seconds.\")\n",
    "\n",
    "    print(\"Best weighted accuracy:\", bestScore)\n",
    "    print(\"Optimal hyperparameters: C=\" + str(bestC) + \", kernel=\" + bestKernel + \", gamma=\" + str(bestGamma))\n",
    "\n",
    "    # get test set accuracy\n",
    "    y_preds_SVM = SVM(X_test, X_train, y_train, bestC, bestKernel, bestGamma)\n",
    "\n",
    "    acc= weighted_accuracy(y_preds_SVM, y_test)\n",
    "    print(\"SVM accuracy\", acc)\n",
    "    \n",
    "    return acc, (bestC, bestKernel, bestGamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2% done. Time to completion: 132.0 seconds.\n",
      "4% done. Time to completion: 129.0 seconds.\n",
      "6% done. Time to completion: 125.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8% done. Time to completion: 394.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11% done. Time to completion: 552.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13% done. Time to completion: 643.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15% done. Time to completion: 702.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17% done. Time to completion: 743.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20% done. Time to completion: 778.0 seconds.\n",
      "22% done. Time to completion: 692.0 seconds.\n",
      "24% done. Time to completion: 621.0 seconds.\n",
      "26% done. Time to completion: 562.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28% done. Time to completion: 570.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31% done. Time to completion: 573.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33% done. Time to completion: 572.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35% done. Time to completion: 570.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37% done. Time to completion: 574.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40% done. Time to completion: 568.0 seconds.\n",
      "42% done. Time to completion: 523.0 seconds.\n",
      "44% done. Time to completion: 482.0 seconds.\n",
      "46% done. Time to completion: 444.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48% done. Time to completion: 446.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51% done. Time to completion: 453.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53% done. Time to completion: 452.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55% done. Time to completion: 443.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57% done. Time to completion: 431.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60% done. Time to completion: 416.0 seconds.\n",
      "62% done. Time to completion: 382.0 seconds.\n",
      "64% done. Time to completion: 350.0 seconds.\n",
      "66% done. Time to completion: 319.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68% done. Time to completion: 307.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71% done. Time to completion: 295.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73% done. Time to completion: 280.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% done. Time to completion: 262.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77% done. Time to completion: 243.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% done. Time to completion: 223.0 seconds.\n",
      "82% done. Time to completion: 194.0 seconds.\n",
      "84% done. Time to completion: 166.0 seconds.\n",
      "86% done. Time to completion: 140.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88% done. Time to completion: 120.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91% done. Time to completion: 98.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93% done. Time to completion: 76.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% done. Time to completion: 52.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97% done. Time to completion: 27.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done. Time to completion: 0.0 seconds.\n",
      "Validation finished after 1222.0 seconds.\n",
      "Hidden Layer Size: 85\n",
      "Activation: relu\n",
      "Alpha: 1e-05\n",
      "Max Iterations: 1500\n",
      "Validation Accuracy: 79.85%\n",
      "Test Accuracy: 74.51%\n",
      "------------\n",
      "0% done. Time to completion: 118.0 seconds.\n",
      "0% done. Time to completion: 108.0 seconds.\n",
      "0% done. Time to completion: 103.0 seconds.\n",
      "0% done. Time to completion: 101.0 seconds.\n",
      "1% done. Time to completion: 99.0 seconds.\n",
      "1% done. Time to completion: 97.0 seconds.\n",
      "1% done. Time to completion: 3277.0 seconds.\n",
      "1% done. Time to completion: 2873.0 seconds.\n",
      "1% done. Time to completion: 2554.0 seconds.\n",
      "2% done. Time to completion: 2298.0 seconds.\n",
      "2% done. Time to completion: 2102.0 seconds.\n",
      "2% done. Time to completion: 1938.0 seconds.\n",
      "2% done. Time to completion: 1795.0 seconds.\n",
      "3% done. Time to completion: 1668.0 seconds.\n",
      "3% done. Time to completion: 1559.0 seconds.\n",
      "3% done. Time to completion: 1462.0 seconds.\n",
      "3% done. Time to completion: 1378.0 seconds.\n",
      "3% done. Time to completion: 1303.0 seconds.\n",
      "4% done. Time to completion: 1236.0 seconds.\n",
      "4% done. Time to completion: 1175.0 seconds.\n",
      "4% done. Time to completion: 1120.0 seconds.\n",
      "4% done. Time to completion: 1070.0 seconds.\n",
      "5% done. Time to completion: 1024.0 seconds.\n",
      "5% done. Time to completion: 982.0 seconds.\n",
      "5% done. Time to completion: 946.0 seconds.\n",
      "5% done. Time to completion: 912.0 seconds.\n",
      "5% done. Time to completion: 881.0 seconds.\n",
      "6% done. Time to completion: 851.0 seconds.\n",
      "6% done. Time to completion: 824.0 seconds.\n",
      "6% done. Time to completion: 799.0 seconds.\n",
      "6% done. Time to completion: 2149.0 seconds.\n",
      "7% done. Time to completion: 2080.0 seconds.\n",
      "7% done. Time to completion: 2014.0 seconds.\n",
      "7% done. Time to completion: 1951.0 seconds.\n",
      "7% done. Time to completion: 1900.0 seconds.\n",
      "7% done. Time to completion: 1851.0 seconds.\n",
      "8% done. Time to completion: 1800.0 seconds.\n",
      "8% done. Time to completion: 1751.0 seconds.\n",
      "8% done. Time to completion: 1703.0 seconds.\n",
      "8% done. Time to completion: 1659.0 seconds.\n",
      "8% done. Time to completion: 1616.0 seconds.\n",
      "9% done. Time to completion: 1576.0 seconds.\n",
      "9% done. Time to completion: 1538.0 seconds.\n",
      "9% done. Time to completion: 1501.0 seconds.\n",
      "9% done. Time to completion: 1466.0 seconds.\n",
      "10% done. Time to completion: 1432.0 seconds.\n",
      "10% done. Time to completion: 1399.0 seconds.\n",
      "10% done. Time to completion: 1368.0 seconds.\n",
      "10% done. Time to completion: 1340.0 seconds.\n",
      "10% done. Time to completion: 1313.0 seconds.\n",
      "11% done. Time to completion: 1288.0 seconds.\n",
      "11% done. Time to completion: 1263.0 seconds.\n",
      "11% done. Time to completion: 1239.0 seconds.\n",
      "11% done. Time to completion: 1216.0 seconds.\n",
      "12% done. Time to completion: 2176.0 seconds.\n",
      "12% done. Time to completion: 2134.0 seconds.\n",
      "12% done. Time to completion: 2092.0 seconds.\n",
      "12% done. Time to completion: 2052.0 seconds.\n",
      "12% done. Time to completion: 2018.0 seconds.\n",
      "13% done. Time to completion: 1986.0 seconds.\n",
      "13% done. Time to completion: 1950.0 seconds.\n",
      "13% done. Time to completion: 1915.0 seconds.\n",
      "13% done. Time to completion: 1880.0 seconds.\n",
      "14% done. Time to completion: 1847.0 seconds.\n",
      "14% done. Time to completion: 1815.0 seconds.\n",
      "14% done. Time to completion: 1784.0 seconds.\n",
      "14% done. Time to completion: 1754.0 seconds.\n",
      "14% done. Time to completion: 1725.0 seconds.\n",
      "15% done. Time to completion: 1697.0 seconds.\n",
      "15% done. Time to completion: 1669.0 seconds.\n",
      "15% done. Time to completion: 1642.0 seconds.\n",
      "15% done. Time to completion: 1616.0 seconds.\n",
      "16% done. Time to completion: 1591.0 seconds.\n",
      "16% done. Time to completion: 1569.0 seconds.\n",
      "16% done. Time to completion: 1546.0 seconds.\n",
      "16% done. Time to completion: 1524.0 seconds.\n",
      "16% done. Time to completion: 1503.0 seconds.\n",
      "17% done. Time to completion: 1482.0 seconds.\n",
      "17% done. Time to completion: 2376.0 seconds.\n",
      "17% done. Time to completion: 2342.0 seconds.\n",
      "17% done. Time to completion: 2308.0 seconds.\n",
      "17% done. Time to completion: 2274.0 seconds.\n",
      "18% done. Time to completion: 2247.0 seconds.\n",
      "18% done. Time to completion: 2219.0 seconds.\n",
      "18% done. Time to completion: 2188.0 seconds.\n",
      "18% done. Time to completion: 2158.0 seconds.\n",
      "19% done. Time to completion: 2128.0 seconds.\n",
      "19% done. Time to completion: 2099.0 seconds.\n",
      "19% done. Time to completion: 2070.0 seconds.\n",
      "19% done. Time to completion: 2043.0 seconds.\n",
      "19% done. Time to completion: 2016.0 seconds.\n",
      "20% done. Time to completion: 1989.0 seconds.\n",
      "20% done. Time to completion: 1963.0 seconds.\n",
      "20% done. Time to completion: 1937.0 seconds.\n",
      "20% done. Time to completion: 1912.0 seconds.\n",
      "21% done. Time to completion: 1888.0 seconds.\n",
      "21% done. Time to completion: 1865.0 seconds.\n",
      "21% done. Time to completion: 1843.0 seconds.\n",
      "21% done. Time to completion: 1821.0 seconds.\n",
      "21% done. Time to completion: 1800.0 seconds.\n",
      "22% done. Time to completion: 1779.0 seconds.\n",
      "22% done. Time to completion: 1758.0 seconds.\n",
      "22% done. Time to completion: 2560.0 seconds.\n",
      "22% done. Time to completion: 2529.0 seconds.\n",
      "23% done. Time to completion: 2499.0 seconds.\n",
      "23% done. Time to completion: 2468.0 seconds.\n",
      "23% done. Time to completion: 2443.0 seconds.\n",
      "23% done. Time to completion: 2418.0 seconds.\n",
      "23% done. Time to completion: 2390.0 seconds.\n",
      "24% done. Time to completion: 2362.0 seconds.\n",
      "24% done. Time to completion: 2334.0 seconds.\n",
      "24% done. Time to completion: 2307.0 seconds.\n",
      "24% done. Time to completion: 2280.0 seconds.\n",
      "25% done. Time to completion: 2254.0 seconds.\n",
      "25% done. Time to completion: 2229.0 seconds.\n",
      "25% done. Time to completion: 2204.0 seconds.\n",
      "25% done. Time to completion: 2179.0 seconds.\n",
      "25% done. Time to completion: 2155.0 seconds.\n",
      "26% done. Time to completion: 2131.0 seconds.\n",
      "26% done. Time to completion: 2107.0 seconds.\n",
      "26% done. Time to completion: 2085.0 seconds.\n",
      "26% done. Time to completion: 2063.0 seconds.\n",
      "26% done. Time to completion: 2042.0 seconds.\n",
      "27% done. Time to completion: 2021.0 seconds.\n",
      "27% done. Time to completion: 2000.0 seconds.\n",
      "27% done. Time to completion: 1980.0 seconds.\n",
      "27% done. Time to completion: 2734.0 seconds.\n",
      "28% done. Time to completion: 2705.0 seconds.\n",
      "28% done. Time to completion: 2677.0 seconds.\n",
      "28% done. Time to completion: 2648.0 seconds.\n",
      "28% done. Time to completion: 2624.0 seconds.\n",
      "28% done. Time to completion: 2600.0 seconds.\n",
      "29% done. Time to completion: 2573.0 seconds.\n",
      "29% done. Time to completion: 2547.0 seconds.\n",
      "29% done. Time to completion: 2520.0 seconds.\n",
      "29% done. Time to completion: 2494.0 seconds.\n",
      "30% done. Time to completion: 2469.0 seconds.\n",
      "30% done. Time to completion: 2444.0 seconds.\n",
      "30% done. Time to completion: 2419.0 seconds.\n",
      "30% done. Time to completion: 2395.0 seconds.\n",
      "30% done. Time to completion: 2371.0 seconds.\n",
      "31% done. Time to completion: 2347.0 seconds.\n",
      "31% done. Time to completion: 2323.0 seconds.\n",
      "31% done. Time to completion: 2300.0 seconds.\n",
      "31% done. Time to completion: 2278.0 seconds.\n",
      "32% done. Time to completion: 2257.0 seconds.\n",
      "32% done. Time to completion: 2235.0 seconds.\n",
      "32% done. Time to completion: 2215.0 seconds.\n",
      "32% done. Time to completion: 2194.0 seconds.\n",
      "32% done. Time to completion: 2173.0 seconds.\n",
      "33% done. Time to completion: 2777.0 seconds.\n",
      "33% done. Time to completion: 2751.0 seconds.\n",
      "33% done. Time to completion: 2724.0 seconds.\n",
      "33% done. Time to completion: 2698.0 seconds.\n",
      "33% done. Time to completion: 2675.0 seconds.\n",
      "34% done. Time to completion: 2653.0 seconds.\n",
      "34% done. Time to completion: 2628.0 seconds.\n",
      "34% done. Time to completion: 2603.0 seconds.\n",
      "34% done. Time to completion: 2578.0 seconds.\n",
      "35% done. Time to completion: 2554.0 seconds.\n",
      "35% done. Time to completion: 2530.0 seconds.\n",
      "35% done. Time to completion: 2506.0 seconds.\n",
      "35% done. Time to completion: 2483.0 seconds.\n",
      "35% done. Time to completion: 2459.0 seconds.\n",
      "36% done. Time to completion: 2436.0 seconds.\n",
      "36% done. Time to completion: 2414.0 seconds.\n",
      "36% done. Time to completion: 2391.0 seconds.\n",
      "36% done. Time to completion: 2369.0 seconds.\n",
      "37% done. Time to completion: 2348.0 seconds.\n",
      "37% done. Time to completion: 2327.0 seconds.\n",
      "37% done. Time to completion: 2306.0 seconds.\n",
      "37% done. Time to completion: 2286.0 seconds.\n",
      "37% done. Time to completion: 2266.0 seconds.\n",
      "38% done. Time to completion: 2246.0 seconds.\n",
      "38% done. Time to completion: 2856.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38% done. Time to completion: 2831.0 seconds.\n",
      "38% done. Time to completion: 2805.0 seconds.\n",
      "39% done. Time to completion: 2779.0 seconds.\n",
      "39% done. Time to completion: 2758.0 seconds.\n",
      "39% done. Time to completion: 2736.0 seconds.\n",
      "39% done. Time to completion: 2712.0 seconds.\n",
      "39% done. Time to completion: 2687.0 seconds.\n",
      "40% done. Time to completion: 2663.0 seconds.\n",
      "40% done. Time to completion: 2639.0 seconds.\n",
      "40% done. Time to completion: 2616.0 seconds.\n",
      "40% done. Time to completion: 2592.0 seconds.\n",
      "41% done. Time to completion: 2569.0 seconds.\n",
      "41% done. Time to completion: 2546.0 seconds.\n",
      "41% done. Time to completion: 2524.0 seconds.\n",
      "41% done. Time to completion: 2501.0 seconds.\n",
      "41% done. Time to completion: 2479.0 seconds.\n",
      "42% done. Time to completion: 2457.0 seconds.\n",
      "42% done. Time to completion: 2436.0 seconds.\n",
      "42% done. Time to completion: 2415.0 seconds.\n",
      "42% done. Time to completion: 2395.0 seconds.\n",
      "42% done. Time to completion: 2374.0 seconds.\n",
      "43% done. Time to completion: 2354.0 seconds.\n",
      "43% done. Time to completion: 2334.0 seconds.\n",
      "43% done. Time to completion: 2906.0 seconds.\n",
      "43% done. Time to completion: 2882.0 seconds.\n",
      "44% done. Time to completion: 2856.0 seconds.\n",
      "44% done. Time to completion: 2831.0 seconds.\n",
      "44% done. Time to completion: 2809.0 seconds.\n",
      "44% done. Time to completion: 2787.0 seconds.\n",
      "44% done. Time to completion: 2762.0 seconds.\n",
      "45% done. Time to completion: 2738.0 seconds.\n",
      "45% done. Time to completion: 2714.0 seconds.\n",
      "45% done. Time to completion: 2691.0 seconds.\n",
      "45% done. Time to completion: 2667.0 seconds.\n",
      "46% done. Time to completion: 2644.0 seconds.\n",
      "46% done. Time to completion: 2621.0 seconds.\n",
      "46% done. Time to completion: 2598.0 seconds.\n",
      "46% done. Time to completion: 2576.0 seconds.\n",
      "46% done. Time to completion: 2553.0 seconds.\n",
      "47% done. Time to completion: 2531.0 seconds.\n",
      "47% done. Time to completion: 2509.0 seconds.\n",
      "47% done. Time to completion: 2488.0 seconds.\n",
      "47% done. Time to completion: 2467.0 seconds.\n",
      "48% done. Time to completion: 2447.0 seconds.\n",
      "48% done. Time to completion: 2426.0 seconds.\n",
      "48% done. Time to completion: 2406.0 seconds.\n",
      "48% done. Time to completion: 2385.0 seconds.\n",
      "48% done. Time to completion: 2847.0 seconds.\n",
      "49% done. Time to completion: 2823.0 seconds.\n",
      "49% done. Time to completion: 2798.0 seconds.\n",
      "49% done. Time to completion: 2774.0 seconds.\n",
      "49% done. Time to completion: 2751.0 seconds.\n",
      "50% done. Time to completion: 2729.0 seconds.\n",
      "50% done. Time to completion: 2705.0 seconds.\n",
      "50% done. Time to completion: 2682.0 seconds.\n",
      "50% done. Time to completion: 2659.0 seconds.\n",
      "50% done. Time to completion: 2636.0 seconds.\n",
      "51% done. Time to completion: 2613.0 seconds.\n",
      "51% done. Time to completion: 2590.0 seconds.\n",
      "51% done. Time to completion: 2567.0 seconds.\n",
      "51% done. Time to completion: 2545.0 seconds.\n",
      "51% done. Time to completion: 2523.0 seconds.\n",
      "52% done. Time to completion: 2501.0 seconds.\n",
      "52% done. Time to completion: 2479.0 seconds.\n",
      "52% done. Time to completion: 2458.0 seconds.\n",
      "52% done. Time to completion: 2437.0 seconds.\n",
      "53% done. Time to completion: 2416.0 seconds.\n",
      "53% done. Time to completion: 2395.0 seconds.\n",
      "53% done. Time to completion: 2375.0 seconds.\n",
      "53% done. Time to completion: 2354.0 seconds.\n",
      "53% done. Time to completion: 2334.0 seconds.\n",
      "54% done. Time to completion: 2654.0 seconds.\n",
      "54% done. Time to completion: 2631.0 seconds.\n",
      "54% done. Time to completion: 2608.0 seconds.\n",
      "54% done. Time to completion: 2585.0 seconds.\n",
      "55% done. Time to completion: 2564.0 seconds.\n",
      "55% done. Time to completion: 2543.0 seconds.\n",
      "55% done. Time to completion: 2520.0 seconds.\n",
      "55% done. Time to completion: 2498.0 seconds.\n",
      "55% done. Time to completion: 2476.0 seconds.\n",
      "56% done. Time to completion: 2454.0 seconds.\n",
      "56% done. Time to completion: 2433.0 seconds.\n",
      "56% done. Time to completion: 2411.0 seconds.\n",
      "56% done. Time to completion: 2390.0 seconds.\n",
      "57% done. Time to completion: 2369.0 seconds.\n",
      "57% done. Time to completion: 2348.0 seconds.\n",
      "57% done. Time to completion: 2327.0 seconds.\n",
      "57% done. Time to completion: 2306.0 seconds.\n",
      "57% done. Time to completion: 2286.0 seconds.\n",
      "58% done. Time to completion: 2266.0 seconds.\n",
      "58% done. Time to completion: 2246.0 seconds.\n",
      "58% done. Time to completion: 2226.0 seconds.\n",
      "58% done. Time to completion: 2206.0 seconds.\n",
      "58% done. Time to completion: 2187.0 seconds.\n",
      "59% done. Time to completion: 2167.0 seconds.\n",
      "59% done. Time to completion: 2436.0 seconds.\n",
      "59% done. Time to completion: 2414.0 seconds.\n",
      "59% done. Time to completion: 2392.0 seconds.\n",
      "60% done. Time to completion: 2371.0 seconds.\n",
      "60% done. Time to completion: 2350.0 seconds.\n",
      "60% done. Time to completion: 2331.0 seconds.\n",
      "60% done. Time to completion: 2309.0 seconds.\n",
      "60% done. Time to completion: 2288.0 seconds.\n",
      "61% done. Time to completion: 2267.0 seconds.\n",
      "61% done. Time to completion: 2247.0 seconds.\n",
      "61% done. Time to completion: 2226.0 seconds.\n",
      "61% done. Time to completion: 2205.0 seconds.\n",
      "62% done. Time to completion: 2185.0 seconds.\n",
      "62% done. Time to completion: 2165.0 seconds.\n",
      "62% done. Time to completion: 2145.0 seconds.\n",
      "62% done. Time to completion: 2125.0 seconds.\n",
      "62% done. Time to completion: 2105.0 seconds.\n",
      "63% done. Time to completion: 2085.0 seconds.\n",
      "63% done. Time to completion: 2066.0 seconds.\n",
      "63% done. Time to completion: 2047.0 seconds.\n",
      "63% done. Time to completion: 2028.0 seconds.\n",
      "64% done. Time to completion: 2009.0 seconds.\n",
      "64% done. Time to completion: 1991.0 seconds.\n",
      "64% done. Time to completion: 1972.0 seconds.\n",
      "64% done. Time to completion: 2185.0 seconds.\n",
      "64% done. Time to completion: 2164.0 seconds.\n",
      "65% done. Time to completion: 2143.0 seconds.\n",
      "65% done. Time to completion: 2123.0 seconds.\n",
      "65% done. Time to completion: 2104.0 seconds.\n",
      "65% done. Time to completion: 2084.0 seconds.\n",
      "66% done. Time to completion: 2064.0 seconds.\n",
      "66% done. Time to completion: 2044.0 seconds.\n",
      "66% done. Time to completion: 2024.0 seconds.\n",
      "66% done. Time to completion: 2004.0 seconds.\n",
      "66% done. Time to completion: 1985.0 seconds.\n",
      "67% done. Time to completion: 1965.0 seconds.\n",
      "67% done. Time to completion: 1946.0 seconds.\n",
      "67% done. Time to completion: 1927.0 seconds.\n",
      "67% done. Time to completion: 1907.0 seconds.\n",
      "67% done. Time to completion: 1888.0 seconds.\n",
      "68% done. Time to completion: 1869.0 seconds.\n",
      "68% done. Time to completion: 1851.0 seconds.\n",
      "68% done. Time to completion: 1832.0 seconds.\n",
      "68% done. Time to completion: 1814.0 seconds.\n",
      "69% done. Time to completion: 1796.0 seconds.\n",
      "69% done. Time to completion: 1778.0 seconds.\n",
      "69% done. Time to completion: 1760.0 seconds.\n",
      "69% done. Time to completion: 1742.0 seconds.\n",
      "69% done. Time to completion: 1900.0 seconds.\n",
      "70% done. Time to completion: 1880.0 seconds.\n",
      "70% done. Time to completion: 1860.0 seconds.\n",
      "70% done. Time to completion: 1841.0 seconds.\n",
      "70% done. Time to completion: 1823.0 seconds.\n",
      "71% done. Time to completion: 1804.0 seconds.\n",
      "71% done. Time to completion: 1785.0 seconds.\n",
      "71% done. Time to completion: 1766.0 seconds.\n",
      "71% done. Time to completion: 1747.0 seconds.\n",
      "71% done. Time to completion: 1728.0 seconds.\n",
      "72% done. Time to completion: 1710.0 seconds.\n",
      "72% done. Time to completion: 1691.0 seconds.\n",
      "72% done. Time to completion: 1673.0 seconds.\n",
      "72% done. Time to completion: 1654.0 seconds.\n",
      "73% done. Time to completion: 1636.0 seconds.\n",
      "73% done. Time to completion: 1618.0 seconds.\n",
      "73% done. Time to completion: 1600.0 seconds.\n",
      "73% done. Time to completion: 1582.0 seconds.\n",
      "73% done. Time to completion: 1565.0 seconds.\n",
      "74% done. Time to completion: 1547.0 seconds.\n",
      "74% done. Time to completion: 1530.0 seconds.\n",
      "74% done. Time to completion: 1512.0 seconds.\n",
      "74% done. Time to completion: 1495.0 seconds.\n",
      "75% done. Time to completion: 1478.0 seconds.\n",
      "75% done. Time to completion: 1623.0 seconds.\n",
      "75% done. Time to completion: 1604.0 seconds.\n",
      "75% done. Time to completion: 1585.0 seconds.\n",
      "75% done. Time to completion: 1566.0 seconds.\n",
      "76% done. Time to completion: 1548.0 seconds.\n",
      "76% done. Time to completion: 1530.0 seconds.\n",
      "76% done. Time to completion: 1512.0 seconds.\n",
      "76% done. Time to completion: 1494.0 seconds.\n",
      "76% done. Time to completion: 1475.0 seconds.\n",
      "77% done. Time to completion: 1457.0 seconds.\n",
      "77% done. Time to completion: 1439.0 seconds.\n",
      "77% done. Time to completion: 1421.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77% done. Time to completion: 1403.0 seconds.\n",
      "78% done. Time to completion: 1386.0 seconds.\n",
      "78% done. Time to completion: 1368.0 seconds.\n",
      "78% done. Time to completion: 1350.0 seconds.\n",
      "78% done. Time to completion: 1333.0 seconds.\n",
      "78% done. Time to completion: 1315.0 seconds.\n",
      "79% done. Time to completion: 1298.0 seconds.\n",
      "79% done. Time to completion: 1281.0 seconds.\n",
      "79% done. Time to completion: 1264.0 seconds.\n",
      "79% done. Time to completion: 1248.0 seconds.\n",
      "80% done. Time to completion: 1231.0 seconds.\n",
      "80% done. Time to completion: 1214.0 seconds.\n",
      "80% done. Time to completion: 1328.0 seconds.\n",
      "80% done. Time to completion: 1310.0 seconds.\n",
      "80% done. Time to completion: 1291.0 seconds.\n",
      "81% done. Time to completion: 1273.0 seconds.\n",
      "81% done. Time to completion: 1255.0 seconds.\n",
      "81% done. Time to completion: 1238.0 seconds.\n",
      "81% done. Time to completion: 1220.0 seconds.\n",
      "82% done. Time to completion: 1202.0 seconds.\n",
      "82% done. Time to completion: 1184.0 seconds.\n",
      "82% done. Time to completion: 1167.0 seconds.\n",
      "82% done. Time to completion: 1149.0 seconds.\n",
      "82% done. Time to completion: 1132.0 seconds.\n",
      "83% done. Time to completion: 1114.0 seconds.\n",
      "83% done. Time to completion: 1097.0 seconds.\n",
      "83% done. Time to completion: 1079.0 seconds.\n",
      "83% done. Time to completion: 1062.0 seconds.\n",
      "83% done. Time to completion: 1045.0 seconds.\n",
      "84% done. Time to completion: 1028.0 seconds.\n",
      "84% done. Time to completion: 1012.0 seconds.\n",
      "84% done. Time to completion: 995.0 seconds.\n",
      "84% done. Time to completion: 978.0 seconds.\n",
      "85% done. Time to completion: 962.0 seconds.\n",
      "85% done. Time to completion: 945.0 seconds.\n",
      "85% done. Time to completion: 929.0 seconds.\n",
      "85% done. Time to completion: 1002.0 seconds.\n",
      "85% done. Time to completion: 984.0 seconds.\n",
      "86% done. Time to completion: 966.0 seconds.\n",
      "86% done. Time to completion: 948.0 seconds.\n",
      "86% done. Time to completion: 931.0 seconds.\n",
      "86% done. Time to completion: 914.0 seconds.\n",
      "87% done. Time to completion: 896.0 seconds.\n",
      "87% done. Time to completion: 879.0 seconds.\n",
      "87% done. Time to completion: 862.0 seconds.\n",
      "87% done. Time to completion: 844.0 seconds.\n",
      "87% done. Time to completion: 827.0 seconds.\n",
      "88% done. Time to completion: 810.0 seconds.\n",
      "88% done. Time to completion: 793.0 seconds.\n",
      "88% done. Time to completion: 776.0 seconds.\n",
      "88% done. Time to completion: 760.0 seconds.\n",
      "89% done. Time to completion: 743.0 seconds.\n",
      "89% done. Time to completion: 726.0 seconds.\n",
      "89% done. Time to completion: 710.0 seconds.\n",
      "89% done. Time to completion: 693.0 seconds.\n",
      "89% done. Time to completion: 677.0 seconds.\n",
      "90% done. Time to completion: 661.0 seconds.\n",
      "90% done. Time to completion: 645.0 seconds.\n",
      "90% done. Time to completion: 629.0 seconds.\n",
      "90% done. Time to completion: 613.0 seconds.\n",
      "91% done. Time to completion: 666.0 seconds.\n",
      "91% done. Time to completion: 648.0 seconds.\n",
      "91% done. Time to completion: 631.0 seconds.\n",
      "91% done. Time to completion: 613.0 seconds.\n",
      "91% done. Time to completion: 596.0 seconds.\n",
      "92% done. Time to completion: 579.0 seconds.\n",
      "92% done. Time to completion: 561.0 seconds.\n",
      "92% done. Time to completion: 544.0 seconds.\n",
      "92% done. Time to completion: 527.0 seconds.\n",
      "92% done. Time to completion: 510.0 seconds.\n",
      "93% done. Time to completion: 493.0 seconds.\n",
      "93% done. Time to completion: 476.0 seconds.\n",
      "93% done. Time to completion: 459.0 seconds.\n",
      "93% done. Time to completion: 442.0 seconds.\n",
      "94% done. Time to completion: 425.0 seconds.\n",
      "94% done. Time to completion: 408.0 seconds.\n",
      "94% done. Time to completion: 392.0 seconds.\n",
      "94% done. Time to completion: 375.0 seconds.\n",
      "94% done. Time to completion: 359.0 seconds.\n",
      "95% done. Time to completion: 342.0 seconds.\n",
      "95% done. Time to completion: 326.0 seconds.\n",
      "95% done. Time to completion: 310.0 seconds.\n",
      "95% done. Time to completion: 294.0 seconds.\n",
      "96% done. Time to completion: 278.0 seconds.\n",
      "96% done. Time to completion: 299.0 seconds.\n",
      "96% done. Time to completion: 280.0 seconds.\n",
      "96% done. Time to completion: 262.0 seconds.\n",
      "96% done. Time to completion: 244.0 seconds.\n",
      "97% done. Time to completion: 226.0 seconds.\n",
      "97% done. Time to completion: 209.0 seconds.\n",
      "97% done. Time to completion: 191.0 seconds.\n",
      "97% done. Time to completion: 173.0 seconds.\n",
      "98% done. Time to completion: 155.0 seconds.\n",
      "98% done. Time to completion: 138.0 seconds.\n",
      "98% done. Time to completion: 120.0 seconds.\n",
      "98% done. Time to completion: 103.0 seconds.\n",
      "98% done. Time to completion: 86.0 seconds.\n",
      "99% done. Time to completion: 68.0 seconds.\n",
      "99% done. Time to completion: 51.0 seconds.\n",
      "99% done. Time to completion: 34.0 seconds.\n",
      "99% done. Time to completion: 17.0 seconds.\n",
      "100% done. Time to completion: 0.0 seconds.\n",
      "Validation finished after 7722.0 seconds.\n",
      "Best weighted accuracy: 0.7059617578862651\n",
      "Optimal hyperparameters: C=8, kernel=rbf, gamma=0.1\n",
      "SVM accuracy 0.7025709219858156\n",
      "------------\n",
      "Neural network is more accurate.\n",
      "Parameters:(85, 'relu', 1e-05, 1500)\n"
     ]
    }
   ],
   "source": [
    "# validate both neural net and svm and choose the one that performs better\n",
    "neural_acc, neural_para = neural_val()\n",
    "print(\"------------\")\n",
    "svm_acc, svm_para = svm_val()\n",
    "print(\"------------\")\n",
    "if neural_acc > svm_acc:\n",
    "    print(\"Neural network is more accurate.\")\n",
    "    print(\"Parameters:\" + str(neural_para))\n",
    "else:\n",
    "    print(\"SVM is more accurate.\")\n",
    "    print(\"Parameters:\" + str(svm_para))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.4 Explanation in Words:</h3><p>\n",
    "    You need to answer the following questions in the markdown cell after this cell:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1 How did you preprocess the dataset and features?\n",
    "\n",
    "> Our preprocessing was done in two steps. In the first step, we read the train dataset as a Pandas dataframe and set the headers. Additionally, we first dropped any features with string values (`County`) as they are hard to use in classification. Then we formatted each column to fit the data type of the feature. Hence, for features `DEM`, `GOP`, and  `FIPS`, we read their values as `int`, for `MedianIncome`, as its values were in string, we had to convert them to `int`. For the rest of the features, we converted them to `float` to accomodate for the decimals. Then, for each county, we had to deduce the winner of the election and create our labels for the training set. Hence, by comparing the numbers of `DEM` and `GOP` for each county, the label would contain the feature with the higher vote count. In our second step, we dropped `DEM` and `GOP` as they are not features provided in the test data (if so, we would have our predictions right away from the test set) and we also dropped `FIPS` as we considered county codes as not informative (they are systematically generated and hence not really affected by the outcome). Lastly, we normalized all our feature vectors so that they would all have mean of 1 and standard deviation of 1.\n",
    "\n",
    "2.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
    "\n",
    "> We used SVM and a simple neural network to make the classification. We thought the SVM was a suitable learning method because first, we have a binary classification problem. We used SVM over other binary classifiers (such as Perceptron) because we had a strong sense that the data will probably not be linearly separable and hence a soft-margin SVM will work better to accommodate for the support vectors. In addition, we could kernelize the classifier using algorithms such as SVM so that our data can be better classified in case the raw distribution is not in a linearly separable shape. In defining our hyperparameters, we tested for different `C` values, different kernels, and different gamma values. We conducted a grid-search 10-fold cross validation on our training set, which then we found our best hyperparameters from our best valdiation score\n",
    ">\n",
    "> Our second choice of using a simple neural network was largely based on our other assumption that the data might not be completely linearly separable (and in some other form of distribution). Based on the algorithms we have learned in class, we thought the neural network was better than other non-linear classification methods such as decision trees and k-NN because we believed decisions trees would be, even with pruning measures, subject to overfitting due to our number of features and k-NN would be subject to noninformative features that may be present. Furthermore, we thought the neural network was the best choice in this regard because by customizing the number of neurons and layers, we could more easily control for overfitting and accuracy. In defining our hyperparameters, we tested for different hidden layer sizes, different activation functions, different values of alpha, and different values of maximum iterations. Due to its larger size of parameters, we did a single-fold validation, where we divided the training data into a training set, a validation set, and a test set, and we chose the hyperparameters that gave the best validation score.\n",
    "\n",
    "2.4.3 How did you do the model selection?\n",
    "\n",
    "> In our model selection, we fed the same training set (which would further be divided into training and validation within each method) and testing set to both learning methods mentioned above (`svm_val` and `neural_val`). We chose to go with a training/testing ratio of 80/20 and we used the same random state number so our train/test split would be same for both.\n",
    ">\n",
    "> For our neural network, we chose to test different parameters for our hidden layer sizes, activation function, alpha, and maximum iteration size. We wanted to test a wide range to ensure that we chose parameters that led to an accurate result without overfitting. Similarly, for our SVM, we chose to test different parameters for our C, kernel function, and alpha. For both our models, if the model selected by our validation chose a parameter that was either a min or max value, we reran the validation introducing new values for that parameter smaller than the min or greater than the max, respectively. This ensured that there were no better parameter values that we were not testing.\n",
    ">\n",
    "> We then chose the model (and its hyperparameters) that gave the higher testing score to submit to Kaggle. In the end, as the above results show, our best model was the neural network with 1 hidden layer consisting of 85 neurons, using a  `ReLu` activation function, an alpha of .00001 and maximum iteration number of 1500.\n",
    "\n",
    "\n",
    "2.4.4 Does the test performance reach a given baseline 68% performance? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    "> With the above model, we submitted to the Kaggle baseline and we have reached over 68% weighted accuracy (72.285% to be exact). We attach a screenshot below.\n",
    ">\n",
    ">![](Basic_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Creative Solution</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.1 Open-ended Code:</h3><p>\n",
    "You may follow the steps in part 2 again but making innovative changes like creating new features, using new training algorithms, etc. Make sure you explain everything clearly in part 3.2. Note that reaching the 75% creative baseline is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you comment your code clearly and you may refer to these comments in the part 3.2\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a FIPS ID of a county and returns a normalized value between -1 and 1 that measures that county's neighbors\n",
    "# affinity for voting DEM/GOP. +1 indicates 100% neighbor voting for DEM and -1 indicates 100% neighbor voting for\n",
    "# GOP.\n",
    "def get_neighbor_score(id):\n",
    "    \n",
    "    # get list of neighbor FIPS ID's\n",
    "    df = pd.read_csv(\"graph.csv\", sep=',',header=0, encoding='unicode_escape')\n",
    "    df = df[df.SRC.eq(id)]\n",
    "    dst = df['DST']\n",
    "    \n",
    "    # load training data\n",
    "    df = pd.read_csv(\"train_2016.csv\", sep=',',header=0, encoding='unicode_escape')\n",
    "    \n",
    "    # create scalar geographic affinity score\n",
    "    score = 0\n",
    "    labeled_counties = 0\n",
    "    for i in dst:\n",
    "        if i != id:\n",
    "            df2 = df[df.FIPS.eq(i)]\n",
    "            dem_list = df2['DEM'].tolist()\n",
    "            if len(dem_list) == 1:\n",
    "                labeled_counties += 1\n",
    "                gop_list = df2['GOP'].tolist()\n",
    "                if dem_list[0] > gop_list[0]:\n",
    "                    score += 1\n",
    "                else:\n",
    "                    score -= 1\n",
    "    if labeled_counties == 0:\n",
    "        normalized_score = 0\n",
    "    else:\n",
    "        normalized_score = score/labeled_counties\n",
    "    \n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same as preprocess but adds a feature to all vectors, which is the neighbor score calculated in the func above\n",
    "def preprocess2(path, labels = True):\n",
    "    df = pd.read_csv(path, sep=',',header=0, encoding='unicode_escape')\n",
    "\n",
    "    # drop non-numerical columns\n",
    "    df = df.drop('County', axis=1)\n",
    "\n",
    "    # type conversions\n",
    "    for col in df.columns:\n",
    "        if col == 'DEM' or col == 'GOP':\n",
    "            df[col] = df[col].astype(int)\n",
    "        elif col == 'MedianIncome':\n",
    "            df[col] = df[col].str.replace(\",\",\"\").astype(int)\n",
    "        elif col == 'FIPS':\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            df[col] = df[col].astype(float)\n",
    "\n",
    "    # replace DEM/GOP columns with a binary results array\n",
    "    if labels == True:\n",
    "        yTr = np.where(df['DEM'] > df['GOP'], 1, 0)\n",
    "        df = df.drop('DEM', axis=1)\n",
    "        df = df.drop('GOP', axis=1)\n",
    "    else:\n",
    "        yTr = df['FIPS']    # for carrying over FIPS ID for testing data\n",
    "    \n",
    "    # add geography feature\n",
    "    geo = []\n",
    "    for i in df['FIPS']:\n",
    "        geo.append(get_neighbor_score(i))\n",
    "    df['Geo'] = geo\n",
    "\n",
    "    # drop FIPS after potentially storing it to yTr\n",
    "    df = df.drop('FIPS', axis=1)\n",
    "            \n",
    "    # normalize\n",
    "    xTr = preprocessing.StandardScaler().fit_transform(df)\n",
    "    \n",
    "    return xTr, yTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same as neural() but drops the activation func as a parameter\n",
    "def neural2(xTe, xTr, yTr, h, a, m):\n",
    "    \n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes = h,\n",
    "        alpha = a,\n",
    "        max_iter = m,\n",
    "        random_state = 7\n",
    "    )\n",
    "    clf.fit(xTr,yTr)\n",
    "    yTe = clf.predict(xTe)\n",
    "    \n",
    "    return yTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate new neural network using the upgraded preprocesser and without activation func as a parameter\n",
    "def neural_val2(xTr, yTr):\n",
    "    # hyperparameters\n",
    "    hidden_layer_sizes = np.arange(80,101,5)\n",
    "    alpha = [.0000001,.000001,.00001]\n",
    "    max_iter = np.arange(1000,3001,500)\n",
    "\n",
    "    # split into test/train/val sets\n",
    "    xTr,xTe,yTr,yTe = train_test_split(xTr, yTr, test_size=.2, random_state=7)\n",
    "    xTr,xVal,yTr,yVal = train_test_split(xTr, yTr, test_size=.2, random_state=7)\n",
    "\n",
    "    # tracker for best neural net hyperparameters\n",
    "    best = (\n",
    "        hidden_layer_sizes[0],\n",
    "        alpha[0],\n",
    "        max_iter[0],\n",
    "           )\n",
    "    best_a = -1\n",
    "\n",
    "    # validate until we have selected good parameters\n",
    "    start = time.time()\n",
    "    z = 1\n",
    "    for h in hidden_layer_sizes:\n",
    "        for a in alpha:\n",
    "            for m in max_iter:\n",
    "                yVal_emp = neural2(xVal, xTr, yTr, h, a, m)\n",
    "                acc = weighted_accuracy(yVal_emp, yVal)\n",
    "                if acc > best_a:\n",
    "                    best_a = acc\n",
    "                    best = (h,a,m)           \n",
    "\n",
    "                # progress tracker\n",
    "                print(str(math.floor(z*100/75))+\"% done. Time to completion: \"+ \n",
    "                      str(int(round(((time.time()-start)/z)*(75-z),0))) +\" seconds.\")\n",
    "                z += 1           \n",
    "    print(\"Validation finished after \"+str(round(time.time()-start,0))+\" seconds.\")\n",
    "\n",
    "    # test the best model with the test set\n",
    "    yTe_emp = neural2(xTe, xTr, yTr,best[0],best[1],best[2])\n",
    "    acc = weighted_accuracy(yTe_emp, yTe)\n",
    "\n",
    "    # print outputs\n",
    "    print(\"Hidden Layer Size: \" + str(best[0]))\n",
    "    print(\"Alpha: \" + str(best[1]))\n",
    "    print(\"Max Iterations: \" + str(best[2]))\n",
    "    print(\"Validation Accuracy: \" + str(round(best_a*100,2)) + \"%\")\n",
    "    print(\"Test Accuracy: \" + str(round(acc*100,2)) + \"%\")\n",
    "    \n",
    "    return acc, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% done. Time to completion: 472 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2% done. Time to completion: 583 seconds.\n",
      "4% done. Time to completion: 642 seconds.\n",
      "5% done. Time to completion: 660 seconds.\n",
      "6% done. Time to completion: 667 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8% done. Time to completion: 622 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done. Time to completion: 621 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% done. Time to completion: 651 seconds.\n",
      "12% done. Time to completion: 669 seconds.\n",
      "13% done. Time to completion: 680 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14% done. Time to completion: 647 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16% done. Time to completion: 634 seconds.\n",
      "17% done. Time to completion: 624 seconds.\n",
      "18% done. Time to completion: 615 seconds.\n",
      "20% done. Time to completion: 604 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21% done. Time to completion: 580 seconds.\n",
      "22% done. Time to completion: 567 seconds.\n",
      "24% done. Time to completion: 554 seconds.\n",
      "25% done. Time to completion: 545 seconds.\n",
      "26% done. Time to completion: 535 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28% done. Time to completion: 518 seconds.\n",
      "29% done. Time to completion: 508 seconds.\n",
      "30% done. Time to completion: 497 seconds.\n",
      "32% done. Time to completion: 487 seconds.\n",
      "33% done. Time to completion: 477 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34% done. Time to completion: 463 seconds.\n",
      "36% done. Time to completion: 453 seconds.\n",
      "37% done. Time to completion: 443 seconds.\n",
      "38% done. Time to completion: 433 seconds.\n",
      "40% done. Time to completion: 429 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41% done. Time to completion: 415 seconds.\n",
      "42% done. Time to completion: 404 seconds.\n",
      "44% done. Time to completion: 393 seconds.\n",
      "45% done. Time to completion: 381 seconds.\n",
      "46% done. Time to completion: 371 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48% done. Time to completion: 359 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49% done. Time to completion: 349 seconds.\n",
      "50% done. Time to completion: 340 seconds.\n",
      "52% done. Time to completion: 331 seconds.\n",
      "53% done. Time to completion: 322 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54% done. Time to completion: 310 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56% done. Time to completion: 301 seconds.\n",
      "57% done. Time to completion: 293 seconds.\n",
      "58% done. Time to completion: 285 seconds.\n",
      "60% done. Time to completion: 276 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61% done. Time to completion: 265 seconds.\n",
      "62% done. Time to completion: 254 seconds.\n",
      "64% done. Time to completion: 244 seconds.\n",
      "65% done. Time to completion: 234 seconds.\n",
      "66% done. Time to completion: 224 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68% done. Time to completion: 214 seconds.\n",
      "69% done. Time to completion: 204 seconds.\n",
      "70% done. Time to completion: 195 seconds.\n",
      "72% done. Time to completion: 186 seconds.\n",
      "73% done. Time to completion: 177 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74% done. Time to completion: 167 seconds.\n",
      "76% done. Time to completion: 159 seconds.\n",
      "77% done. Time to completion: 150 seconds.\n",
      "78% done. Time to completion: 141 seconds.\n",
      "80% done. Time to completion: 133 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81% done. Time to completion: 123 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82% done. Time to completion: 115 seconds.\n",
      "84% done. Time to completion: 107 seconds.\n",
      "85% done. Time to completion: 98 seconds.\n",
      "86% done. Time to completion: 90 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88% done. Time to completion: 80 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89% done. Time to completion: 72 seconds.\n",
      "90% done. Time to completion: 63 seconds.\n",
      "92% done. Time to completion: 54 seconds.\n",
      "93% done. Time to completion: 45 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94% done. Time to completion: 36 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96% done. Time to completion: 27 seconds.\n",
      "97% done. Time to completion: 18 seconds.\n",
      "98% done. Time to completion: 9 seconds.\n",
      "100% done. Time to completion: 0 seconds.\n",
      "Validation finished after 693.0 seconds.\n",
      "Hidden Layer Size: 90\n",
      "Alpha: 1e-06\n",
      "Max Iterations: 2000\n",
      "Validation Accuracy: 79.38%\n",
      "Test Accuracy: 73.75%\n"
     ]
    }
   ],
   "source": [
    "# load xTr and yTr\n",
    "xTr, yTr = preprocess2(\"train_2016.csv\")\n",
    "\n",
    "# validate\n",
    "neural_acc, neural_para = neural_val2(xTr,yTr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2 Explanation in Words:</h3><p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to answer the following questions in a markdown cell after this cell:\n",
    "\n",
    "3.2.1 How much did you manage to improve performance on the test set compared to part 2? Did you reach the 75% accuracy for the test in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    ">For our creative solution, we were able to reach the 75% accuracy mark on the creative Kaggle competition with a score of 75.103%. Compared to part 2, we increased our accuracy by about 3%.\n",
    ">\n",
    ">![](Creative_screenshot.png)\n",
    "\n",
    "3.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this.\n",
    "\n",
    "> We decided to further pursue neural networks because from our previous part, it gave a much higher test accuracy than SVM. From extensive validation testing from part 2, it was clear that `ReLu` consistently produced results with the highest test accuracy, so for part 3 we fixed `ReLu` as a custom parameter of our neural network in order to expedite the validation processing time.\n",
    ">\n",
    "> Our main strategy for part 3 was to boost our neural network by taking advantage of geographic location. Specifically, with `graph.csv`, we knew, for any given county, all the counties that bordered it. Additionally, with our training data, we knew the voting results of many of these counties. Our thinking was that we could evaluate how a county's neighbors voted and there was a good chance that the county would vote similar to its neighbors. We wanted to create a new feature for all our data that would represent this \"geographic neighbor voting affinity\".\n",
    ">\n",
    "> Our algorithm to do this is as follows: for any county, initialize their score to be 0 and use `graph.csv` to look at all its neighboring counties. Then, for each of these counties, we check to see if we know how they voted. If we do not know how they voted, unfortunately that data point becomes useless to us. However, if we do know how they voted, if they voted DEM, we add +1 to the score, and if they voted GOP, we add -1 to the score. After tallying up all its neighbors, we then normalize this score to fit between -1 and +1. As an example, if a county has 6 neighbors and we know that 3 of them voted DEM and 2 of them voted GOP, they would have a raw score of +1. After normalization, it becomes +0.2.\n",
    ">\n",
    "> We ran this algorithm for each county to generate a new feature entirely in the preprocesser function. We then ran the same neural network validation algorithm (minus activation function as a custom parameter), and the model it selected was a neural network with 1 hidden layer with 90 neurons, an alpha of .000001, and a max iteration count of 2000. This model was able to get us above the 75% threshold of the Kaggle creative competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4: Kaggle Submission</h2><p>\n",
    "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The CSV shall contain TWO column named exactly \"FIPS\" and \"Result\" and 1555 total rows excluding the column names, \"FIPS\" column shall contain FIPS of counties with same order as in the test_2016_no_label.csv while \"Result\" column shall contain the 0 or 1 prdicaitons for corresponding columns. A sample predication file can be downloaded from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic kaggle submission\n",
    "\n",
    "# import data\n",
    "xTr, yTr = preprocess(\"train_2016.csv\")\n",
    "xTe, FIPS = preprocess(\"test_2016_no_label.csv\", labels = False)\n",
    "\n",
    "# predict\n",
    "yTe = neural(xTe, xTr, yTr, 85, 'relu', .00001, 1500)\n",
    "\n",
    "# write to csv\n",
    "d = {'FIPS': FIPS,'Result': yTe}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv(\"Submission_basic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creative kaggle submission\n",
    "\n",
    "# import data\n",
    "xTr, yTr = preprocess2(\"train_2016.csv\")\n",
    "xTe, FIPS = preprocess2(\"creative_csv/test_2016_no_label_creative.csv\", labels = False)\n",
    "\n",
    "# predict\n",
    "yTe = neural2(xTe, xTr, yTr, 90, .000001, 2000)\n",
    "\n",
    "# write to csv\n",
    "d = {'FIPS': FIPS,'Result': yTe}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv(\"Submission_creative.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 5: Resources and Literature Used</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we used `pandas` and `numpy` to read and manipulate csv training and testing csv files. Additionally, we used scikit for the bulk of our machine learning algorithms. This includes `preprocessing` and `svm` from sklearn, as well as `train_test_split` and `KFold` from `sklearn.model_selection` and `MLPClassifier` from `sklearn.neural_network`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
